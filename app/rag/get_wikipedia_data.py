from wikipedia import wikipedia
import re

def clean_wikipedia_text(content: str) -> str:
    """
    Limpia especÃ­ficamente texto de artÃ­culos de Wikipedia para RAG.
    Elimina marcado especÃ­fico de Wikipedia y mejora la legibilidad.
    """
    
    # 1. Eliminar secciones de referencias y enlaces externos
    content = re.sub(r"== Referencias ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Enlaces externos ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== VÃ©ase tambiÃ©n ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== BibliografÃ­a ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== PseudocÃ³digo ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Algoritmo ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Esquema ==.*?(?=== |$)", "", content, flags=re.DOTALL)

    # 2. Eliminar texto entre llaves {} - plantillas, fÃ³rmulas, etc.
    content = re.sub(r"\{[^}]*\}", "", content)
    
    # 3. Limpiar expresiones matemÃ¡ticas LaTeX/MathML
    # Eliminar bloques de fÃ³rmulas matemÃ¡ticas que aparecen como texto plano
    content = re.sub(r"\s*\{\s*\\displaystyle[^}]*\}\s*", " ", content)
    content = re.sub(r"\s*\{\s*\\[a-zA-Z]+[^}]*\}\s*", " ", content)
        
    # 4. Limpiar encabezados de secciÃ³n (convertir === === a formato mÃ¡s limpio)
    content = re.sub(r"^=+\s*(.+?)\s*=+$", r"\1:", content, flags=re.MULTILINE)
    
    # 5. Eliminar lÃ­neas que contengan solo espacios y caracteres especiales
    content = re.sub(r"^\s*[âŠ†âˆªâˆ–âˆ…â‰ â†â†’âˆˆ]+\s*$", "", content, flags=re.MULTILINE)
    
    # 6. Eliminar referencias a figuras, imÃ¡genes y tablas
    content = re.sub(r"\[\[Archivo:.*?\]\]", "", content)
    content = re.sub(r"\[\[Imagen:.*?\]\]", "", content)
    content = re.sub(r"\[\[File:.*?\]\]", "", content)
    
    # 7. Limpiar enlaces internos de Wikipedia [[enlace|texto]] -> texto
    content = re.sub(r"\[\[([^|\]]+)\|([^\]]+)\]\]", r"\2", content)  # [[enlace|texto]] -> texto
    content = re.sub(r"\[\[([^\]]+)\]\]", r"\1", content)  # [[enlace]] -> enlace
    
    # 8. Eliminar plantillas y parÃ¡metros {{plantilla}} (redundante con paso 2, pero se mantiene por seguridad)
    content = re.sub(r"\{\{[^}]*\}\}", "", content)
        
    # Eliminar bloques de cÃ³digo que contengan palabras clave de programaciÃ³n
    content = re.sub(r"procedure\s+\w+.*?end procedure\.?", "", content, flags=re.DOTALL | re.IGNORECASE)
    content = re.sub(r"algorithm\s+\w+.*?end algorithm\.?", "", content, flags=re.DOTALL | re.IGNORECASE)
    
    # Eliminar lÃ­neas tÃ­picas de pseudocÃ³digo
    content = re.sub(r"^\s*(while|if|begin|end).*$", "", content, flags=re.MULTILINE | re.IGNORECASE)
    content = re.sub(r"^\s*(for each|while|if|then|else|endif|endfor|endwhile|do|begin|end).*$", "", content, flags=re.MULTILINE | re.IGNORECASE)
    
    # Eliminar lÃ­neas con operadores de asignaciÃ³n y comparaciÃ³n tÃ­picos de pseudocÃ³digo
    content = re.sub(r"^\s*\w+\s*(:=|=|â†|â†’|\+=|-=)\s*.*$", "", content, flags=re.MULTILINE)
    
    # 10. Eliminar lÃ­neas con pocos caracteres (menos de 10 caracteres Ãºtiles)
    # Esto elimina lÃ­neas que solo contienen espacios, nÃºmeros sueltos, o texto muy corto
    lines = content.split('\n')
    filtered_lines = []
    for line in lines:
        # Conservar lÃ­neas vacÃ­as para mantener la estructura de pÃ¡rrafos
        if line.strip() == "":
            filtered_lines.append(line)
        # Conservar lÃ­neas con al menos 10 caracteres Ãºtiles (sin espacios)
        elif len(re.sub(r'[^\w\s]', '', line.strip())) >= 10:
            filtered_lines.append(line)
        # Conservar encabezados cortos que terminan en ":"
        elif line.strip().endswith(':') and len(line.strip()) > 3:
            filtered_lines.append(line)
    content = '\n'.join(filtered_lines)
            
    # 11. Normalizar espacios mÃºltiples
    content = re.sub(r" {2,}", " ", content)
    
    # 12. Eliminar lÃ­neas vacÃ­as mÃºltiples
    content = re.sub(r"\n\s*\n\s*\n", "\n\n", content)
    
    
    return content.strip()

def get_wikipedia_article(query: str, lang: str = "es") -> dict:
    """
    Obtiene un artÃ­culo de Wikipedia y lo limpia para RAG.
    
    Args:
        query: TÃ©rmino de bÃºsqueda
        lang: Idioma de Wikipedia (por defecto espaÃ±ol)
    
    Returns:
        Dict con tÃ­tulo, contenido limpio, resumen y metadatos
    """
    try:
        wikipedia.set_lang(lang)
        
        # Buscar el artÃ­culo
        search_results = wikipedia.search(query, results=5)
        if not search_results:
            return None
        
        # Intentar obtener la pÃ¡gina con el primer resultado
        page = wikipedia.page(search_results[0])
        
        # Limpiar el contenido
        cleaned_content = clean_wikipedia_text(page.content)
        
        return {
            "title": page.title,
            "url": page.url,
            "summary": page.summary,
            "content": cleaned_content,
            "categories": getattr(page, 'categories', []),
            "lang": lang,
            "search_query": query
        }
        
    except wikipedia.DisambiguationError as e:
        # Si hay desambiguaciÃ³n, tomar la primera opciÃ³n
        try:
            page = wikipedia.page(e.options[0])
            cleaned_content = clean_wikipedia_text(page.content)
            return {
                "title": page.title,
                "url": page.url,
                "summary": page.summary,
                "content": cleaned_content,
                "categories": getattr(page, 'categories', []),
                "lang": lang,
                "search_query": query
            }
        except Exception as inner_e:
            print(f"Error al procesar pÃ¡gina desambiguada: {inner_e}")
            return None
            
    except wikipedia.PageError:
        print(f"No se encontrÃ³ la pÃ¡gina para: {query}")
        return None
    except Exception as e:
        print(f"Error inesperado: {e}")
        return None

def save_wikipedia_articles(queries: list, output_dir: str = "data/wikipedia", lang: str = "es"):
    """
    Descarga y guarda mÃºltiples artÃ­culos de Wikipedia limpiados.
    
    Args:
        queries: Lista de tÃ©rminos de bÃºsqueda
        output_dir: Directorio donde guardar los archivos
        lang: Idioma de Wikipedia
    """
    import os
    import json
    
    # Crear directorio si no existe
    os.makedirs(output_dir, exist_ok=True)
    
    for query in queries:
        print(f"Procesando: {query}")
        article_data = get_wikipedia_article(query, lang)
        
        if article_data:
            # Crear nombre de archivo seguro
            safe_filename = re.sub(r'[^\w\s-]', '', article_data['title']).strip()
            safe_filename = re.sub(r'[-\s]+', '-', safe_filename)
            
            # Guardar contenido limpio como texto
            text_file = os.path.join(output_dir, f"{safe_filename}.txt")
            with open(text_file, "w", encoding="utf-8") as f:
                f.write(f"{article_data['content']}")
                        
            print(f"âœ… Guardado: {safe_filename}")
        else:
            print(f"âŒ No se pudo procesar: {query}")

def process_terminos_clave(
    terminos_file: str = "./terminos_clave.md", 
    base_output_dir: str = "data",
    lang: str = "es"
):
    """
    Lee el archivo terminos_clave.md y descarga artÃ­culos de Wikipedia
    organizados por secciones.
    
    Args:
        terminos_file: Ruta al archivo terminos_clave.md
        base_output_dir: Directorio base donde crear las carpetas por secciÃ³n
        lang: Idioma de Wikipedia
    """
    import os
    
    try:
        with open(terminos_file, "r", encoding="utf-8") as f:
            content = f.read()
    except FileNotFoundError:
        print(f"âŒ No se encontrÃ³ el archivo: {terminos_file}")
        return
    except Exception as e:
        print(f"âŒ Error al leer el archivo: {e}")
        return
    
    # Parsear el contenido por secciones
    sections = {}
    current_section = None
    
    for line in content.split('\n'):
        line = line.strip()
        
        # Detectar nueva secciÃ³n (lÃ­neas que empiezan con #)
        if line.startswith('# '):
            current_section = line[2:].strip()  # Quitar '# '
            sections[current_section] = []
            print(f"ğŸ“ SecciÃ³n encontrada: {current_section}")
            
        # Agregar tÃ©rminos a la secciÃ³n actual (lÃ­neas no vacÃ­as que no empiecen con #)
        elif line and not line.startswith('#') and current_section:
            sections[current_section].append(line)
    
    print(f"\nğŸ“‹ Total de secciones encontradas: {len(sections)}")
    
    # Procesar cada secciÃ³n
    for section_name, terms in sections.items():
        if not terms:  # Saltar secciones vacÃ­as
            continue
            
        print(f"\nğŸ”„ Procesando secciÃ³n: {section_name}")
        print(f"ğŸ“ TÃ©rminos a procesar: {len(terms)}")
        
        # Crear directorio para la secciÃ³n
        section_dir = os.path.join(base_output_dir, section_name)
        os.makedirs(section_dir, exist_ok=True)
        
        # Procesar cada tÃ©rmino en la secciÃ³n
        successful_downloads = 0
        failed_downloads = 0
        
        for i, term in enumerate(terms, 1):
            print(f"  [{i}/{len(terms)}] Descargando: {term}")
            
            article_data = get_wikipedia_article(term, lang)
            
            if article_data:
                # Crear nombre de archivo seguro
                safe_filename = re.sub(r'[^\w\s-]', '', term).strip()
                safe_filename = re.sub(r'[-\s]+', '-', safe_filename)
                
                # Guardar contenido limpio como texto
                text_file = os.path.join(section_dir, f"{safe_filename}.txt")
                
                try:
                    with open(text_file, "w", encoding="utf-8") as f:
                        # Incluir metadatos al inicio del archivo
                        f.write(article_data['content'])
                    
                    print(f"    âœ… Guardado: {safe_filename}.txt")
                    successful_downloads += 1
                    
                except Exception as e:
                    print(f"    âŒ Error al guardar {safe_filename}: {e}")
                    failed_downloads += 1
            else:
                print(f"    âŒ No se pudo obtener: {term}")
                failed_downloads += 1
        
        print(f"  ğŸ“Š SecciÃ³n {section_name}: {successful_downloads} exitosos, {failed_downloads} fallidos")
    
    print(f"\nğŸ‰ Proceso completado. Revisa el directorio '{base_output_dir}' para ver los resultados.")

# Ejemplo de uso y test
if __name__ == "__main__":
    import sys
    
    # Configurar idioma de Wikipedia
    wikipedia.set_lang("es")
    
    print("=== PROCESADOR DE TÃ‰RMINOS CLAVE DE WIKIPEDIA ===")
    print("Este script procesarÃ¡ el archivo terminos_clave.md y descargarÃ¡")
    print("artÃ­culos de Wikipedia organizados por secciones.\n")
    
    # Permitir argumentos de lÃ­nea de comandos para personalizar
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help" or sys.argv[1] == "-h":
            print("Uso:")
            print("  python get_wikipedia_data.py                    # Usar configuraciÃ³n por defecto")
            print("  python get_wikipedia_data.py --custom          # ConfiguraciÃ³n personalizada")
            print("  python get_wikipedia_data.py --test TÃ‰RMINO    # Probar con un tÃ©rmino especÃ­fico")
            print("  python get_wikipedia_data.py --help            # Mostrar esta ayuda")
            sys.exit(0)
        
        elif sys.argv[1] == "--test" and len(sys.argv) > 2:
            # Modo test con un tÃ©rmino especÃ­fico
            test_term = " ".join(sys.argv[2:])
            print(f"=== MODO TEST: {test_term} ===")
            article = get_wikipedia_article(test_term)
            
            if article:
                print(f"âœ… TÃ­tulo: {article['title']}")
                print(f"ğŸ”— URL: {article['url']}")
                print(f"ğŸ“ Resumen: {article['summary'][:200]}...")
                print(f"ğŸ“„ Contenido: {len(article['content'])} caracteres")
                
                # Guardar el artÃ­culo de prueba
                with open(f"test_{test_term.replace(' ', '_')}.txt", "w", encoding="utf-8") as f:
                    f.write(article['content'])
                print(f"ğŸ’¾ Guardado en: test_{test_term.replace(' ', '_')}.txt")
            else:
                print(f"âŒ No se pudo obtener el artÃ­culo para: {test_term}")
            sys.exit(0)
        
        elif sys.argv[1] == "--custom":
            # Modo personalizado
            print("=== CONFIGURACIÃ“N PERSONALIZADA ===")
            terminos_file = input("Archivo de tÃ©rminos [app/rag/terminos_clave.md]: ").strip()
            if not terminos_file:
                terminos_file = "app/rag/terminos_clave.md"
            
            output_dir = input("Directorio de salida [data]: ").strip()
            if not output_dir:
                output_dir = "data"
            
            lang = input("Idioma Wikipedia [es]: ").strip()
            if not lang:
                lang = "es"
            
            wikipedia.set_lang(lang)
            process_terminos_clave(terminos_file, output_dir, lang)
            sys.exit(0)
    
    # Modo por defecto: procesar tÃ©rminos clave
    print("Iniciando procesamiento con configuraciÃ³n por defecto...")
    print("ğŸ“ Archivo: ./terminos_clave.md")
    print("ğŸ“‚ Directorio de salida: data/")
    print("ğŸŒ Idioma: espaÃ±ol")
    print("=" * 60)
    
    try:
        process_terminos_clave()
        print("\nğŸ‰ Â¡Procesamiento completado exitosamente!")
        print("ğŸ’¡ Consejo: Usa --help para ver mÃ¡s opciones")
    except KeyboardInterrupt:
        print("\nâš ï¸  Proceso interrumpido por el usuario")
    except Exception as e:
        print(f"\nâŒ Error durante el procesamiento: {e}")
        print("ğŸ’¡ Prueba con --test TÃ‰RMINO para verificar la conectividad")
