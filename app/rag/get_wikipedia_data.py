from wikipedia import wikipedia
import re

def clean_wikipedia_text(content: str) -> str:
    """
    Limpia espec√≠ficamente texto de art√≠culos de Wikipedia para RAG.
    Elimina marcado espec√≠fico de Wikipedia y mejora la legibilidad.
    """
    
    # 1. Eliminar secciones de referencias y enlaces externos
    content = re.sub(r"== Referencias ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Enlaces externos ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== V√©ase tambi√©n ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Bibliograf√≠a ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Pseudoc√≥digo ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Algoritmo ==.*?(?=== |$)", "", content, flags=re.DOTALL)
    content = re.sub(r"== Esquema ==.*?(?=== |$)", "", content, flags=re.DOTALL)

    # 2. Eliminar texto entre llaves {} - plantillas, f√≥rmulas, etc.
    content = re.sub(r"\{[^}]*\}", "", content)
    
    # 3. Limpiar expresiones matem√°ticas LaTeX/MathML
    # Eliminar bloques de f√≥rmulas matem√°ticas que aparecen como texto plano
    content = re.sub(r"\s*\{\s*\\displaystyle[^}]*\}\s*", " ", content)
    content = re.sub(r"\s*\{\s*\\[a-zA-Z]+[^}]*\}\s*", " ", content)
        
    # 4. Limpiar encabezados de secci√≥n (convertir === === a formato m√°s limpio)
    content = re.sub(r"^=+\s*(.+?)\s*=+$", r"\1:", content, flags=re.MULTILINE)
    
    # 5. Eliminar l√≠neas que contengan solo espacios y caracteres especiales
    content = re.sub(r"^\s*[‚äÜ‚à™‚àñ‚àÖ‚â†‚Üê‚Üí‚àà]+\s*$", "", content, flags=re.MULTILINE)
    
    # 6. Eliminar referencias a figuras, im√°genes y tablas
    content = re.sub(r"\[\[Archivo:.*?\]\]", "", content)
    content = re.sub(r"\[\[Imagen:.*?\]\]", "", content)
    content = re.sub(r"\[\[File:.*?\]\]", "", content)
    
    # 7. Limpiar enlaces internos de Wikipedia [[enlace|texto]] -> texto
    content = re.sub(r"\[\[([^|\]]+)\|([^\]]+)\]\]", r"\2", content)  # [[enlace|texto]] -> texto
    content = re.sub(r"\[\[([^\]]+)\]\]", r"\1", content)  # [[enlace]] -> enlace
    
    # 8. Eliminar plantillas y par√°metros {{plantilla}} (redundante con paso 2, pero se mantiene por seguridad)
    content = re.sub(r"\{\{[^}]*\}\}", "", content)
        
    # Eliminar bloques de c√≥digo que contengan palabras clave de programaci√≥n
    content = re.sub(r"procedure\s+\w+.*?end procedure\.?", "", content, flags=re.DOTALL | re.IGNORECASE)
    content = re.sub(r"algorithm\s+\w+.*?end algorithm\.?", "", content, flags=re.DOTALL | re.IGNORECASE)
    
    # Eliminar l√≠neas t√≠picas de pseudoc√≥digo
    content = re.sub(r"^\s*(while|if|begin|end).*$", "", content, flags=re.MULTILINE | re.IGNORECASE)
    content = re.sub(r"^\s*(for each|while|if|then|else|endif|endfor|endwhile|do|begin|end).*$", "", content, flags=re.MULTILINE | re.IGNORECASE)
    
    # Eliminar l√≠neas con operadores de asignaci√≥n y comparaci√≥n t√≠picos de pseudoc√≥digo
    content = re.sub(r"^\s*\w+\s*(:=|=|‚Üê|‚Üí|\+=|-=)\s*.*$", "", content, flags=re.MULTILINE)
    
    # 10. Eliminar l√≠neas con pocos caracteres (menos de 10 caracteres √∫tiles)
    # Esto elimina l√≠neas que solo contienen espacios, n√∫meros sueltos, o texto muy corto
    lines = content.split('\n')
    filtered_lines = []
    for line in lines:
        # Conservar l√≠neas vac√≠as para mantener la estructura de p√°rrafos
        if line.strip() == "":
            filtered_lines.append(line)
        # Conservar l√≠neas con al menos 10 caracteres √∫tiles (sin espacios)
        elif len(re.sub(r'[^\w\s]', '', line.strip())) >= 10:
            filtered_lines.append(line)
        # Conservar encabezados cortos que terminan en ":"
        elif line.strip().endswith(':') and len(line.strip()) > 3:
            filtered_lines.append(line)
    content = '\n'.join(filtered_lines)
            
    # 11. Normalizar espacios m√∫ltiples
    content = re.sub(r" {2,}", " ", content)
    
    # 12. Eliminar l√≠neas vac√≠as m√∫ltiples
    content = re.sub(r"\n\s*\n\s*\n", "\n\n", content)
    
    
    return content.strip()

def get_wikipedia_article(query: str, lang: str = "es") -> dict:
    """
    Obtiene un art√≠culo de Wikipedia y lo limpia para RAG.
    
    Args:
        query: T√©rmino de b√∫squeda
        lang: Idioma de Wikipedia (por defecto espa√±ol)
    
    Returns:
        Dict con t√≠tulo, contenido limpio, resumen y metadatos
    """
    try:
        wikipedia.set_lang(lang)
        
        # Buscar el art√≠culo
        search_results = wikipedia.search(query, results=5)
        if not search_results:
            return None
        
        # Intentar obtener la p√°gina con el primer resultado
        page = wikipedia.page(search_results[0])
        
        # Limpiar el contenido
        cleaned_content = clean_wikipedia_text(page.content)
        
        return {
            "title": page.title,
            "url": page.url,
            "summary": page.summary,
            "content": cleaned_content,
            "categories": getattr(page, 'categories', []),
            "lang": lang,
            "search_query": query
        }
        
    except wikipedia.DisambiguationError as e:
        # Si hay desambiguaci√≥n, tomar la primera opci√≥n
        try:
            page = wikipedia.page(e.options[0])
            cleaned_content = clean_wikipedia_text(page.content)
            return {
                "title": page.title,
                "url": page.url,
                "summary": page.summary,
                "content": cleaned_content,
                "categories": getattr(page, 'categories', []),
                "lang": lang,
                "search_query": query
            }
        except Exception as inner_e:
            print(f"Error al procesar p√°gina desambiguada: {inner_e}")
            return None
            
    except wikipedia.PageError:
        print(f"No se encontr√≥ la p√°gina para: {query}")
        return None
    except Exception as e:
        print(f"Error inesperado: {e}")
        return None

def save_wikipedia_articles(queries: list, output_dir: str = "data/wikipedia", lang: str = "es"):
    """
    Descarga y guarda m√∫ltiples art√≠culos de Wikipedia limpiados.
    
    Args:
        queries: Lista de t√©rminos de b√∫squeda
        output_dir: Directorio donde guardar los archivos
        lang: Idioma de Wikipedia
    """
    import os
    import json
    
    # Crear directorio si no existe
    os.makedirs(output_dir, exist_ok=True)
    
    for query in queries:
        print(f"Procesando: {query}")
        article_data = get_wikipedia_article(query, lang)
        
        if article_data:
            # Crear nombre de archivo seguro
            safe_filename = re.sub(r'[^\w\s-]', '', article_data['title']).strip()
            safe_filename = re.sub(r'[-\s]+', '-', safe_filename)
            
            # Guardar contenido limpio como texto
            text_file = os.path.join(output_dir, f"{safe_filename}.txt")
            with open(text_file, "w", encoding="utf-8") as f:
                f.write(f"{article_data['content']}")
                        
            print(f"‚úÖ Guardado: {safe_filename}")
        else:
            print(f"‚ùå No se pudo procesar: {query}")

def process_terminos_clave(
    terminos_file: str = "./terminos_clave.md", 
    base_output_dir: str = "data",
    lang: str = "es"
):
    """
    Lee el archivo terminos_clave.md y descarga art√≠culos de Wikipedia
    organizados por secciones.
    
    Args:
        terminos_file: Ruta al archivo terminos_clave.md
        base_output_dir: Directorio base donde crear las carpetas por secci√≥n
        lang: Idioma de Wikipedia
    """
    import os
    
    try:
        with open(terminos_file, "r", encoding="utf-8") as f:
            content = f.read()
    except FileNotFoundError:
        print(f"‚ùå No se encontr√≥ el archivo: {terminos_file}")
        return
    except Exception as e:
        print(f"‚ùå Error al leer el archivo: {e}")
        return
    
    # Parsear el contenido por secciones
    sections = {}
    current_section = None
    
    for line in content.split('\n'):
        line = line.strip()
        
        # Detectar nueva secci√≥n (l√≠neas que empiezan con #)
        if line.startswith('# '):
            current_section = line[2:].strip()  # Quitar '# '
            sections[current_section] = []
            print(f"üìÅ Secci√≥n encontrada: {current_section}")
            
        # Agregar t√©rminos a la secci√≥n actual (l√≠neas no vac√≠as que no empiecen con #)
        elif line and not line.startswith('#') and current_section:
            sections[current_section].append(line)
    
    print(f"\nüìã Total de secciones encontradas: {len(sections)}")
    
    # Procesar cada secci√≥n
    for section_name, terms in sections.items():
        if not terms:  # Saltar secciones vac√≠as
            continue
            
        print(f"\nüîÑ Procesando secci√≥n: {section_name}")
        print(f"üìù T√©rminos a procesar: {len(terms)}")
        
        # Crear directorio para la secci√≥n
        section_dir = os.path.join(base_output_dir, section_name)
        os.makedirs(section_dir, exist_ok=True)
        
        # Procesar cada t√©rmino en la secci√≥n
        successful_downloads = 0
        failed_downloads = 0
        
        for i, term in enumerate(terms, 1):
            print(f"  [{i}/{len(terms)}] Descargando: {term}")
            
            article_data = get_wikipedia_article(term, lang)
            
            if article_data:
                # Crear nombre de archivo seguro
                safe_filename = re.sub(r'[^\w\s-]', '', term).strip()
                safe_filename = re.sub(r'[-\s]+', '-', safe_filename)
                
                # Guardar contenido limpio como texto
                text_file = os.path.join(section_dir, f"{safe_filename}.txt")
                
                try:
                    with open(text_file, "w", encoding="utf-8") as f:
                        # Incluir metadatos al inicio del archivo
                        f.write(article_data['content'])
                    
                    print(f"    ‚úÖ Guardado: {safe_filename}.txt")
                    successful_downloads += 1
                    
                except Exception as e:
                    print(f"    ‚ùå Error al guardar {safe_filename}: {e}")
                    failed_downloads += 1
            else:
                print(f"    ‚ùå No se pudo obtener: {term}")
                failed_downloads += 1
        
        print(f"  üìä Secci√≥n {section_name}: {successful_downloads} exitosos, {failed_downloads} fallidos")
    
    print(f"\nüéâ Proceso completado. Revisa el directorio '{base_output_dir}' para ver los resultados.")

# Ejemplo de uso y test
if __name__ == "__main__":
    import sys
    
    # Configurar idioma de Wikipedia
    wikipedia.set_lang("es")
    
    print("=== PROCESADOR DE T√âRMINOS CLAVE DE WIKIPEDIA ===")
    print("Este script procesar√° el archivo terminos_clave.md y descargar√°")
    print("art√≠culos de Wikipedia organizados por secciones.\n")
    
    # Permitir argumentos de l√≠nea de comandos para personalizar
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help" or sys.argv[1] == "-h":
            print("Uso:")
            print("  python get_wikipedia_data.py                    # Usar configuraci√≥n por defecto")
            print("  python get_wikipedia_data.py --custom          # Configuraci√≥n personalizada")
            print("  python get_wikipedia_data.py --test T√âRMINO    # Probar con un t√©rmino espec√≠fico")
            print("  python get_wikipedia_data.py --help            # Mostrar esta ayuda")
            sys.exit(0)
        
        elif sys.argv[1] == "--test" and len(sys.argv) > 2:
            # Modo test con un t√©rmino espec√≠fico
            test_term = " ".join(sys.argv[2:])
            print(f"=== MODO TEST: {test_term} ===")
            article = get_wikipedia_article(test_term)
            
            if article:
                print(f"‚úÖ T√≠tulo: {article['title']}")
                print(f"üîó URL: {article['url']}")
                print(f"üìù Resumen: {article['summary'][:200]}...")
                print(f"üìÑ Contenido: {len(article['content'])} caracteres")
                
                # Guardar el art√≠culo de prueba
                with open(f"test_{test_term.replace(' ', '_')}.txt", "w", encoding="utf-8") as f:
                    f.write(article['content'])
                print(f"üíæ Guardado en: test_{test_term.replace(' ', '_')}.txt")
            else:
                print(f"‚ùå No se pudo obtener el art√≠culo para: {test_term}")
            sys.exit(0)
        
        elif sys.argv[1] == "--custom":
            # Modo personalizado
            print("=== CONFIGURACI√ìN PERSONALIZADA ===")
            terminos_file = input("Archivo de t√©rminos [app/rag/terminos_clave.md]: ").strip()
            if not terminos_file:
                terminos_file = "app/rag/terminos_clave.md"
            
            output_dir = input("Directorio de salida [data]: ").strip()
            if not output_dir:
                output_dir = "data"
            
            lang = input("Idioma Wikipedia [es]: ").strip()
            if not lang:
                lang = "es"
            
            wikipedia.set_lang(lang)
            process_terminos_clave(terminos_file, output_dir, lang)
            sys.exit(0)
    
    # Modo por defecto: procesar t√©rminos clave
    print("Iniciando procesamiento con configuraci√≥n por defecto...")
    print("üìÅ Archivo: ./terminos_clave.md")
    print("üìÇ Directorio de salida: data/")
    print("üåê Idioma: espa√±ol")
    print("=" * 60)
    
    try:
        process_terminos_clave()
        print("\nüéâ ¬°Procesamiento completado exitosamente!")
        print("üí° Consejo: Usa --help para ver m√°s opciones")
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Proceso interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error durante el procesamiento: {e}")
        print("üí° Prueba con --test T√âRMINO para verificar la conectividad")
