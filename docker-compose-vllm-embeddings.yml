services:
    vllm-openai-embeddings:
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          device_ids: ['0']
                          capabilities:
                              - gpu
        volumes:
            - ./models:/models
        environment:
            HUGGING_FACE_HUB_TOKEN: ${HF_TOKEN}
        ports:
            - 8001:8001
        ipc: host
        image: vllm/vllm-openai:latest
        command: --model /models/Qwen--Qwen3-Embedding-0.6B --port 8001 --max-num-seqs 8 --gpu-memory-utilization 0.8 --max_model_len=3000
    chatbot:
        build:
            context: .
            dockerfile: Containerfile
        ports:
            - 5001:5001
        environment:
            HF_HUB_DISABLE_SYMLINKS_WARNING: 1
        volumes:
        - ./.env:/app/.env
        - ./app/app.py:/app/app.py
        - ./app/router_logic.py:/app/router_logic.py
        - ./app/logic/query_logic.py:/app/query_logic.py
        - ./app/RAG/get_embedding_function.py:/app/get_embedding_function.py
        - ./app/RAG/populate_database.py:/app/populate_database.py
        - ./app/logic/graph.py:/app/graph.py
        - ./models:/app/models
        - ./data:/app/data
        - ./logs:/app/logs
        - ./graphs:/app/graphs
        - ./app/RAG/chroma:/app/chroma
        - ./static:/app/static
        - ./templates:/app/templates

        restart: unless-stopped