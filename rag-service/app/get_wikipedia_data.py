#!/usr/bin/env python3
"""
Script para extraer contenido de Wikipedia y poblar el RAG Service
VersiÃ³n migrada al RAG Service - Obtiene artÃ­culos de Wikipedia como contenido RAG
"""
import wikipedia
import re
import argparse
import sys
import requests
import tempfile
from pathlib import Path
from typing import List, Optional, Set
import time

# ConfiguraciÃ³n
DEFAULT_RAG_SERVICE_URL = "http://localhost:8082"

class WikipediaRAGPopulator:
    """Clase para extraer contenido de Wikipedia y enviarlo al RAG Service"""
    
    def __init__(self, rag_service_url: str = DEFAULT_RAG_SERVICE_URL, language: str = 'es'):
        self.rag_service_url = rag_service_url
        self.language = language
        wikipedia.set_lang(language)
        
    def check_rag_service(self) -> bool:
        """Verificar que el RAG Service estÃ© disponible"""
        try:
            response = requests.get(f"{self.rag_service_url}/health", timeout=5)
            return response.status_code == 200
        except Exception as e:
            print(f"âŒ Error conectando al RAG Service: {e}")
            return False
    
    def clean_wikipedia_text(self, content: str) -> str:
        """
        Limpia especÃ­ficamente texto de artÃ­culos de Wikipedia para RAG.
        Elimina marcado especÃ­fico de Wikipedia y mejora la legibilidad.
        """
        
        # 1. Eliminar secciones de referencias y enlaces externos
        content = re.sub(r"== Referencias ==.*?(?=== |$)", "", content, flags=re.DOTALL)
        content = re.sub(r"== Enlaces externos ==.*?(?=== |$)", "", content, flags=re.DOTALL)
        content = re.sub(r"== VÃ©ase tambiÃ©n ==.*?(?=== |$)", "", content, flags=re.DOTALL)
        content = re.sub(r"== BibliografÃ­a ==.*?(?=== |$)", "", content, flags=re.DOTALL)
        content = re.sub(r"== PseudocÃ³digo ==.*?(?=== |$)", "", content, flags=re.DOTALL)
        content = re.sub(r"== Algoritmo ==.*?(?=== |$)", "", content, flags=re.DOTALL)
        content = re.sub(r"== Esquema ==.*?(?=== |$)", "", content, flags=re.DOTALL)

        # 2. Eliminar texto entre llaves {} - plantillas, fÃ³rmulas, etc.
        content = re.sub(r"\{[^}]*\}", "", content)
        
        # 3. Limpiar expresiones matemÃ¡ticas LaTeX/MathML
        # Eliminar bloques de fÃ³rmulas matemÃ¡ticas que aparecen como texto plano
        content = re.sub(r"\s*\{\s*\\displaystyle[^}]*\}\s*", " ", content)
        content = re.sub(r"\s*\{\s*\\[a-zA-Z]+[^}]*\}\s*", " ", content)
            
        # 4. Limpiar encabezados de secciÃ³n (convertir === === a formato mÃ¡s limpio)
        content = re.sub(r"^=+\s*(.+?)\s*=+$", r"\1:", content, flags=re.MULTILINE)
        
        # 5. Eliminar lÃ­neas que contengan solo espacios y caracteres especiales
        content = re.sub(r"^\s*[âŠ†âˆªâˆ–âˆ…â‰ â†â†’âˆˆ]+\s*$", "", content, flags=re.MULTILINE)
        
        # 6. Eliminar referencias a figuras, imÃ¡genes y tablas
        content = re.sub(r"\[\[Archivo:.*?\]\]", "", content)
        content = re.sub(r"\[\[Imagen:.*?\]\]", "", content)
        content = re.sub(r"\[\[File:.*?\]\]", "", content)
        
        # 7. Limpiar enlaces internos de Wikipedia [[enlace|texto]] -> texto
        content = re.sub(r"\[\[([^|\]]+)\|([^\]]+)\]\]", r"\2", content)  # [[enlace|texto]] -> texto
        content = re.sub(r"\[\[([^\]]+)\]\]", r"\1", content)  # [[enlace]] -> enlace
        
        # 8. Eliminar plantillas y parÃ¡metros {{plantilla}} (redundante con paso 2, pero se mantiene por seguridad)
        content = re.sub(r"\{\{[^}]*\}\}", "", content)
            
        # Eliminar bloques de cÃ³digo que contengan palabras clave de programaciÃ³n
        content = re.sub(r"procedure\s+\w+.*?end procedure\.?", "", content, flags=re.DOTALL | re.IGNORECASE)
        content = re.sub(r"algorithm\s+\w+.*?end algorithm\.?", "", content, flags=re.DOTALL | re.IGNORECASE)
        
        # Eliminar lÃ­neas tÃ­picas de pseudocÃ³digo
        content = re.sub(r"^\s*(while|if|begin|end).*$", "", content, flags=re.MULTILINE | re.IGNORECASE)
        
        # 9. Normalizar espacios mÃºltiples y lÃ­neas vacÃ­as
        content = re.sub(r"[ \t]+", " ", content)  # Espacios mÃºltiples -> un espacio
        content = re.sub(r"\n{3,}", "\n\n", content)  # MÃ¡ximo dos saltos de lÃ­nea
        
        # 10. Eliminar lÃ­neas que sean solo nÃºmeros o caracteres especiales
        content = re.sub(r"^\s*\d+\s*$", "", content, flags=re.MULTILINE)
        content = re.sub(r"^\s*[^\w\s]+\s*$", "", content, flags=re.MULTILINE)
        
        return content.strip()
    
    def search_wikipedia_articles(self, query: str, max_results: int = 10) -> List[str]:
        """Buscar artÃ­culos de Wikipedia relacionados con una consulta"""
        try:
            print(f"ğŸ” Buscando artÃ­culos de Wikipedia para: '{query}'")
            search_results = wikipedia.search(query, results=max_results)
            print(f"ğŸ“„ Encontrados {len(search_results)} artÃ­culos potenciales")
            return search_results
        except Exception as e:
            print(f"âŒ Error buscando en Wikipedia: {e}")
            return []
    
    def get_wikipedia_article(self, title: str) -> Optional[str]:
        """Obtener contenido completo de un artÃ­culo de Wikipedia"""
        try:
            print(f"ğŸ“– Obteniendo artÃ­culo: {title}")
            
            # Obtener pÃ¡gina con retry en caso de ambigÃ¼edad
            try:
                page = wikipedia.page(title, auto_suggest=True)
            except wikipedia.DisambiguationError as e:
                # Si hay ambigÃ¼edad, tomar la primera opciÃ³n
                print(f"âš ï¸  AmbigÃ¼edad detectada para '{title}', usando: {e.options[0]}")
                page = wikipedia.page(e.options[0])
            except wikipedia.PageError:
                print(f"âŒ PÃ¡gina no encontrada: {title}")
                return None
            
            # Obtener contenido y limpiar
            content = page.content
            cleaned_content = self.clean_wikipedia_text(content)
            
            if len(cleaned_content) < 200:  # ArtÃ­culo muy corto
                print(f"âš ï¸  ArtÃ­culo muy corto, omitiendo: {title}")
                return None
            
            # AÃ±adir metadatos al inicio
            article_text = f"# {page.title}\n\n"
            article_text += f"**URL:** {page.url}\n\n"
            article_text += cleaned_content
            
            print(f"âœ… ArtÃ­culo obtenido: {title} ({len(cleaned_content)} caracteres)")
            return article_text
            
        except Exception as e:
            print(f"âŒ Error obteniendo artÃ­culo '{title}': {e}")
            return None
    
    def get_multiple_articles(self, terms: List[str], max_per_term: int = 3) -> List[str]:
        """Obtener mÃºltiples artÃ­culos de Wikipedia"""
        all_articles = []
        processed_titles = set()  # Para evitar duplicados
        
        for term in terms:
            print(f"\nğŸ” Procesando tÃ©rmino: {term}")
            
            # Buscar artÃ­culos relacionados
            search_results = self.search_wikipedia_articles(term, max_results=max_per_term * 2)
            
            articles_for_term = 0
            for title in search_results:
                if articles_for_term >= max_per_term:
                    break
                
                if title.lower() in processed_titles:
                    print(f"â­ï¸  Omitiendo duplicado: {title}")
                    continue
                
                article_content = self.get_wikipedia_article(title)
                if article_content:
                    all_articles.append(article_content)
                    processed_titles.add(title.lower())
                    articles_for_term += 1
                
                # Pausa para evitar rate limiting
                time.sleep(0.5)
        
        print(f"\nğŸ“š Total de artÃ­culos obtenidos: {len(all_articles)}")
        return all_articles
    
    def populate_rag_from_wikipedia(self, terms: List[str], subject_name: str, 
                                   max_per_term: int = 3, reset: bool = False) -> bool:
        """Obtener artÃ­culos de Wikipedia y poblar RAG Service"""
        try:
            # Obtener artÃ­culos
            articles = self.get_multiple_articles(terms, max_per_term)
            
            if not articles:
                print("âŒ No se pudieron obtener artÃ­culos de Wikipedia")
                return False
            
            # Crear archivos temporales para cada artÃ­culo
            temp_files = []
            try:
                for i, article in enumerate(articles):
                    temp_file = tempfile.NamedTemporaryFile(
                        mode='w', 
                        suffix=f'_wikipedia_article_{i+1}.txt',
                        delete=False, 
                        encoding='utf-8'
                    )
                    temp_file.write(article)
                    temp_file.close()
                    temp_files.append(temp_file.name)
                
                # Preparar archivos para envÃ­o
                files = []
                for temp_path in temp_files:
                    with open(temp_path, 'rb') as f:
                        filename = f"wikipedia_{Path(temp_path).stem}.txt"
                        files.append(('files', (filename, f.read(), 'text/plain')))
                
                # Enviar al RAG Service
                data = {
                    'subject': subject_name,
                    'reset': str(reset).lower()
                }
                
                print(f"\nğŸ”„ Enviando {len(files)} artÃ­culos al RAG Service...")
                response = requests.post(
                    f"{self.rag_service_url}/populate",
                    files=files,
                    data=data,
                    timeout=300  # 5 minutos
                )
                
                if response.status_code == 200:
                    result = response.json()
                    chunks_added = result.get('chunks_added', 0)
                    processed_files = result.get('processed_files', [])
                    failed_files = result.get('failed_files', [])
                    
                    print(f"âœ… Wikipedia para {subject_name} poblada exitosamente")
                    print(f"ğŸ“Š Chunks aÃ±adidos: {chunks_added}")
                    print(f"ğŸ“Š Archivos procesados: {len(processed_files)}")
                    
                    if failed_files:
                        print(f"âš ï¸  Archivos fallidos: {len(failed_files)}")
                    
                    return True
                else:
                    print(f"âŒ Error poblando RAG Service: HTTP {response.status_code}")
                    print(f"   Detalle: {response.text}")
                    return False
            
            finally:
                # Limpiar archivos temporales
                for temp_path in temp_files:
                    try:
                        Path(temp_path).unlink()
                    except:
                        pass
                        
        except Exception as e:
            print(f"âŒ Error procesando Wikipedia: {e}")
            return False
    
    def save_articles_locally(self, terms: List[str], output_dir: str = "wikipedia_articles", 
                             max_per_term: int = 3) -> bool:
        """Guardar artÃ­culos de Wikipedia localmente"""
        try:
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)
            
            articles = self.get_multiple_articles(terms, max_per_term)
            
            for i, article in enumerate(articles):
                # Extraer tÃ­tulo del artÃ­culo
                title_match = re.match(r"# (.+)", article)
                title = title_match.group(1) if title_match else f"articulo_{i+1}"
                
                # Crear nombre de archivo seguro
                safe_filename = re.sub(r'[^\w\s-]', '', title)
                safe_filename = re.sub(r'[-\s]+', '_', safe_filename)
                
                file_path = output_path / f"{safe_filename}.txt"
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(article)
                
                print(f"ğŸ’¾ Guardado: {file_path}")
            
            print(f"\nğŸ‰ {len(articles)} artÃ­culos guardados en {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ Error guardando artÃ­culos: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(
        description="Extraer artÃ­culos de Wikipedia y poblar RAG Service",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  # Poblar con tÃ©rminos especÃ­ficos
  python get_wikipedia_data.py --terms "algoritmo genÃ©tico" "metaheurÃ­stica" "optimizaciÃ³n" --subject "metaheuristicas"
  
  # MÃ¡s artÃ­culos por tÃ©rmino
  python get_wikipedia_data.py --terms "estadÃ­stica" "probabilidad" --subject "estadistica" --max-per-term 5
  
  # Resetear antes de poblar
  python get_wikipedia_data.py --terms "servidor web" "nginx" --subject "servidores" --reset
  
  # Solo guardar localmente sin poblar RAG
  python get_wikipedia_data.py --terms "algoritmo" --save-only --output-dir "articulos_algoritmos"
  
  # Usar Wikipedia en inglÃ©s
  python get_wikipedia_data.py --terms "genetic algorithm" --subject "algorithms" --language "en"
        """
    )
    
    parser.add_argument(
        "--terms", 
        nargs="+",
        required=True,
        help="TÃ©rminos de bÃºsqueda para Wikipedia"
    )
    parser.add_argument(
        "--subject", 
        help="Nombre de la asignatura para el RAG Service (requerido si no se usa --save-only)"
    )
    parser.add_argument(
        "--max-per-term", 
        type=int,
        default=3,
        help="MÃ¡ximo nÃºmero de artÃ­culos por tÃ©rmino (por defecto: 3)"
    )
    parser.add_argument(
        "--rag-url", 
        default=DEFAULT_RAG_SERVICE_URL,
        help=f"URL del RAG Service (por defecto: {DEFAULT_RAG_SERVICE_URL})"
    )
    parser.add_argument(
        "--reset", 
        action="store_true",
        help="Resetear base de datos de la asignatura antes de poblar"
    )
    parser.add_argument(
        "--language", 
        default="es",
        help="Idioma de Wikipedia (por defecto: es)"
    )
    parser.add_argument(
        "--save-only", 
        action="store_true",
        help="Solo guardar artÃ­culos localmente sin poblar RAG Service"
    )
    parser.add_argument(
        "--output-dir", 
        default="wikipedia_articles",
        help="Directorio para guardar artÃ­culos localmente (por defecto: wikipedia_articles)"
    )
    
    args = parser.parse_args()
    
    # Validar argumentos
    if not args.save_only and not args.subject:
        print("âŒ --subject es requerido cuando no se usa --save-only")
        sys.exit(1)
    
    print("ğŸ“š Wikipedia RAG Populator")
    print(f"ğŸ” TÃ©rminos: {args.terms}")
    print(f"ğŸ“Š Max por tÃ©rmino: {args.max_per_term}")
    print(f"ğŸŒ Idioma: {args.language}")
    
    if args.save_only:
        print(f"ğŸ’¾ Modo: Solo guardar en {args.output_dir}")
    else:
        print(f"ğŸ“š Asignatura: {args.subject}")
        print(f"ğŸ”„ Reset: {'SÃ­' if args.reset else 'No'}")
        print(f"ğŸŒ RAG Service: {args.rag_url}")
    
    print("=" * 70)
    
    # Crear populator
    populator = WikipediaRAGPopulator(args.rag_url, args.language)
    
    if args.save_only:
        # Solo guardar localmente
        success = populator.save_articles_locally(
            terms=args.terms,
            output_dir=args.output_dir,
            max_per_term=args.max_per_term
        )
    else:
        # Verificar RAG Service
        if not populator.check_rag_service():
            print("âŒ RAG Service no estÃ¡ disponible")
            sys.exit(1)
        print("âœ… RAG Service disponible")
        
        # Poblar RAG Service
        success = populator.populate_rag_from_wikipedia(
            terms=args.terms,
            subject_name=args.subject,
            max_per_term=args.max_per_term,
            reset=args.reset
        )
    
    if success:
        print("\nğŸ‰ Proceso completado exitosamente")
    else:
        print("\nâŒ Proceso fallÃ³")
        sys.exit(1)


if __name__ == "__main__":
    main()
